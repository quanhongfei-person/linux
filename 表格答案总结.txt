1. sizeof和strlen的区别
	1.sizeof是操作符，strlen是库函数
	2.sizeof的参数可以是数据类型、变量名，而strlen的参数只能是以‘\0’结尾的字符串
	3.sizeof和strlen的执行时间，操作符在预处理时，函数在执行时
	
2. 指针的优点
	1.可以提高程序的编译效率和执行速度，使程序更加简洁
	2.通过指针可以直接操作内存地址

3. 野指针、空指针、
	空指针：空指针不指向任何实际的对象或函数，NULL是一个标准规定的宏定义，用来表示空指针常量
	野指针：不知道指向哪里，或者说指向的内存空间不知道是否可以操作，
	产生原因：指针变量未初始化；指针free或delete后没有设置为null，让人误以为是合法指针；指针操作越界
	
4. 什么是内存碎片内存泄露，区别，内存申请及销毁原理：
	内存泄露：调用malloc函数，没有进行释放，造成内存泄漏
	内存溢出：堆：malloc时，没有足够的空间
	内存申请及销毁原理：因为堆上分配的空间都有一个表头，存储了被分配内存的大小和起始地址，malloc函数只有在申请内存失败，才会返回null，
		malloc(0)认为我们申请内存成功，返回的是一个正常的地址，也就是说操作系统实际分配了4字节内存空间，但可用内存空间为0，即返回的指针不能用;	

5. C语言编译流程
	C语言编译过程分成四个步骤： 
		①由.c文件到.i文件（-E），这个过程叫预处理 ，读取C语言源程序，对其中的伪指令
			1.删除所有#define，并且展开所有的宏定义
			2.处理所有的条件编译
			3.处理所有的#include预编译指定，将被包含的头文件插入到该编译指令的位置。
			4.删除所有的注释
			5.添加行号和文件名标识
		②由.i文件到.s文件(-S)，这个过程叫编译 ， 编译过程是整个程序构建的核心部分，编译成功，
			会将源代码由文本形式转换成汇编语言，编译过程就是把预处理完的文件进行一系列词法分析、
			语法分析、语义分析以及优化后生成相应的汇编代码文件。
		③由.s文件到.o文件(-c)，汇编过程调用汇编器as来完成，是用于将汇编代码转换成机器可以执行的指令，每一个汇编语句几乎都对应一条机器指令。
		④由.o文件到可执行文件，这个过程叫链接，链接的主要内容就是将各个模块之间相互引用的部分正确的衔接起来。
			它的工作就是把一些指令对其他符号地址的引用加以修正。
		
		链接过程主要包括了符号解析和重定向
			1.符号解析
				符号可以是一个函数、全局变量或一个静态变量，其实就是指用符号来去标识一个地址。
				比如说 int a = 6;这样一句代码，用a来标识一个块4个字节大小的空间，空间里边存放的内容就是4.	
			2.重定位（地址回填）
				顾名思义，重新定位的意思。多个目标文件合并后相对于合并前的重新定位。文件a调用文件b中的函数或者变量时，需要知道其地址。但是未链接前，
				因为不在同一个文件，所以文件a不道其引用函数的地址，暂时用0x00000000或者其他临时假地址代替，真正的地址计算工作留给了链接器。链接器在完成地址
				和空间分配之后就已经可以确定所有符号的虚拟地址了，那么链接器就可以根据符号的地址对每个需要重定位的指令进行地址修正了。
		
				最基本的链接叫做静态链接，就是将每个模块的源代码文件编译成目标文件（Linux：.o  Windows：.obj），然后将目标文件和库一起链接形成最后的可执行文件。
				库其实就是一组目标文件的包，就是一些最常用的代码变异成目标文件后打包存放。最常见的库就是运行时库，它是支持程序运行的基本函数的集合。
				动态链接多调用的函数代码并没有被拷贝到应用程序的可执行文件当中，仅仅在其中加入了所调用函数的描述信息。只有应用程序被装入内存开始运行后，才会调用。

6. makefile如何编写
	makefile定义了一系列的规则来指定，哪些文件需要先编译，哪些文件需要后编译，哪些文件需要重新编译，甚至可以在makefile中执行shell脚本。
	makefile带来的好处就是——“自动化编译”，一旦写好，只需要一个make命令，整个工程完全自动编译，极大的提高了软件开发的效率
	makefile是一个文件，make是一个工具，用来解释makefile中的指令。
	Makefile格式：
		1.一个规则
			目标：依赖条件
				命令
		note：①目标的时间必须晚于依赖条件的时间，否则更新目标
			  ②依赖条件如果不存在，找寻新的规则去产生依赖
			  ③Makefile文件中默认把第一组规则中的目标作为终极目标，用all：终极目标，可以指定终极目标
		2.函数：wildcard：可以进行文件匹配
		        patsubst：内容替换
		3.自动变量：$@：在规则的命令中，代表目标
		                    $^：在规则的命令中，代表全部依赖
		                    $<：在规则的命令中，代表第一个依赖，如果将$<应用在模式规则中，它可将依赖条件列表中的依赖条件依次取出，套用模式规则
		                    $?：在规则的命令中，所有比目标新的依赖的集合，以空格隔分
		4.伪目标：伪目标就是没有条件，只有目标和命令，然后再目标前面加了.PHONY关键字声明。它不代表一个真正的文件名，是一个“虚假”的目标。
			常见伪目标：all、clean、install（安装已经编译好的程序）、print（列出改变过的源文件）
		                .PHONY：clean all声明clean是伪目标

7. 可执行程序分为哪几部分
	代码区：存放程序编译后的二进制代码
	常量区：存放字符串常量和只读变量
	全局（静态）存储区：存放全局变量和静态全局变量、静态局部变量。
			  初始化的全局变量和静态变量在一块区域，未初始化的全局变量和未初始化的静态变量在相邻的另一块区域。因此，又可以分为.data段和.bss段。
			  data段：存放已初始化的全局和静态变量。在编译器编译的时候，会给已初始化的数据分配内存空间，数据保存在目标文件中。
			  .bss段：存放未初始化或初始化为0的全局和静态变量。在编译器编译的时候，不会给该段的数据分配空间，只是记录数据所需的空间大小。
	堆区：由程序员手动申请/释放，若不手动释放，程序结束后由系统回收.【malloc申请的内存】
	栈区：由系统自动分配，存放函数参数、局部变量等
	
	从编译和执行的角度描述如下：可执行二进制程序 = 代码段(.text)＋初始化数据段(.data)+未初始化数据段(.bss)
		当程序被加载到内存单元时，则需要另外两个域：堆域和栈域，
		正在运行的C程序 = 代码段(.text)+初始化数据段(.data)+未初始化数据段(.bss)+堆(.heap)+栈（.stack）

2.进程和线程的区别
	进程：一个在内存中运行的应用程序，占用系统资源。
	线程：进程中的一个执行单元，负责当前进程中程序的执行。
	区别总结：
		 ①根本区别：进程是操作系统资源分配的基本单位，而线程是处理器任务调度和执行的基本单位
		 ②资源开销：每个进程都有独立的代码和数据空间（程序上下文），程序之间的切换会有较大的开销；
					线程可以看做轻量级的进程，同一类线程共享代码和数据空间，
					每个线程都有自己独立的运行栈和程序计数器（PC），线程之间切换的开销小。即线程有独立的PCB，但地址空间共享;
		 ③包含关系：如果一个进程内有多个线程，则执行过程不是一条线的，而是多条线（线程）共同完成的；线程是进程的一部分
		 ④内存分配：同一进程的线程共享本进程的地址空间和资源，而进程之间的地址空间和资源是相互独立的。
		 ⑤影响关系：一个进程崩溃后，在保护模式下不会对其他进程产生影响，但是一个线程崩溃整个进程都死掉。所以多进程要比多线程健壮。
		 ⑥执行过程：每个独立的进程有程序运行的入口、顺序执行序列和程序出口。但是线程不能独立执行，必须依存在应用程序中，由应用程序提供多个线程执行控制，两者均可并发执行

进程和线程的优缺点：
	多线程多进程
		多进程优点：
			1.编程容易，通常不需要考虑锁和同步资源的问题
			2.更强的容错性：一个进程崩溃，不会影响另一个进程
			3.每个进程间都有独立的地址空间和资源
		多进程缺点：
			1.逻辑控制复杂，需要和主程序交互
			2.开销大
		多线程优点：
			1.创建速度快，方便高效的数据共享
			2.线程间切换开销小
		缺点：
			1.线程之间同步与加锁控制比较麻烦
			2.一个线程的崩溃影响到整个程序的稳定
			3.到达一定的线程数后，即使再增加CPU也不能提高性能，
			4.每个线程与主程序公用地址，受限于0~4G的地址空间
				
进程和线程的使用场景：
	1.需要频繁创建销毁，优先考虑线程，比如web服务器
	2.需要进行大量计算（频繁切换cpu）的优先考虑线程
	3.强相关的处理用线程，弱相关用进程，比如消息收发和消息处理就是弱相关，消息处理中的消息解码和业务处理就是强相关
	在实际应用中，基本上都是“进程+线程”的结合方式	

12.进程间通信方式
	管道pipe：半双工的通信方式，数据只能单向流动，有血缘关系的进程使用
	命名管道fifo：半双工，任意进程使用；
	共享内存：直接分配一个共享空间，每个进程都可以访问，最快，当多个进程竞争共享资源时会造成数据的错乱
	信号：异步通信机制，但是不能携带数据
	套接字：可以跨网络与不同主机进程通信；
	mmap映射：


	
	
	
9.什么是死锁；
	定义：两个或多个进程在执行过程中，由于竞争资源而造成的一种阻塞现象
	产生必要条件：
		互斥条件：一个资源每次只能被一个进程使用
		请求和保持条件：一个进程因请求资源而阻塞时，对已经获得的资源保持不放
		不抢占条件：进程已获得的资源，在未使用完之前，不能强行剥夺
		循环等待条件：若干进程之间形成一种头为相连的循环等待资源关系

		
	

7.快排算法思想和实现
	思想：快速排序使用分治的思想，通过一趟排序将待排序列分割成两部分，其中一部分记录的关键字均比另一部分记录的关键字小。
		之后分别对这两部分记录进行递归排序，以达到整个序列有序的目的。
	实现原理：①首先设定一个分界值，这里我一般取数组第一个值，通过该分界值将数组分成左右两部分
		 ②从后往前遍历数组，将最后的值与基准值比较，如果大于基准值，若小于基准值，
		 ③从前往后遍历数组
int find_pos(int *arr,int low,int high)
{
    int val = arr[0];
    while(low < high)
    {
		while(low<high &&arr[high] >= val)
	        high--;
		arr[low] = arr[high];
		while(low < high &&arr[low] <= val)
	        low++;
		arr[high] = arr[low];
    }
    arr[low] = val;
    return low;
}
void quick_sort(int *arr,int high,int low)
{
    if(low >= high)
		return ;
    int pos;
    if(low < high)
    {
		pos = find_pos(arr,low,high);
		quick_sort(arr,low,pos-1);
		quick_sort(arr,pos+1,high);
    }
}	
	
	
	
	
	
	
	
	
	
	
	
0.1虚拟内存和物理内存
	1.虚拟内存
		进程得到的这4G虚拟内存是一个连续的地址空间（这也只是进程认为），而实际上，它通常是被分隔成多个物理内存碎片，
		还有一部分存储在外部磁盘存储器上，在需要时进行数据交换。
	2.进程开始要访问一个地址，它可能会经历下面的过程
		1.每次我要访问地址空间上的某一个地址，都需要把地址翻译为实际物理内存地址
		2.所有进程共享这整一块物理内存，每个进程只把自己目前需要的虚拟地址空间映射到物理内存上
		3.进程需要知道哪些地址空间上的数据在物理内存上，哪些不在（可能这部分存储在磁盘上），还有在物理内存上的哪里，这就需要通过页表来记录
		4.页表的每一个表项分两部分，第一部分记录此页是否在物理内存上，第二部分记录物理内存页的地址（如果在的话）
		5.当进程访问某个虚拟地址的时候，就会先去看页表，如果发现对应的数据不在物理内存上，就会发生缺页异常
		6.缺页异常的处理过程，操作系统立即阻塞该进程，并将硬盘里对应的页换入内存，然后使该进程就绪，如果内存已经满了，没有空地方了，那就找一个页覆盖，至于具体覆盖的哪个页，就需要看操作系统的页面置换算法是怎么设计的了。
	MMU：
		内存管理单元，负责虚拟地址和物理地址的转换


0.3怎么理解面向对象和面向过程
	面向过程就是分析出解决问题所需要的步骤，然后用函数把这些步骤一步一步实现，使用的时候一个一个依次调用就可以了；
	面向对象是把构成问题事务分解成各个对象，建立对象的目的不是为了完成一个步骤，而是为了描叙某个事物在整个解决问题的步骤中的行为。

	可以拿生活中的实例来理解面向过程与面向对象，例如五子棋，
	面向过程的设计思路就是首先分析问题的步骤：
		1、开始游戏，2、黑子先走，3、绘制画面，4、判断输赢，5、轮到白子，6、绘制画面，7、判断输赢，8、返回步骤2，9、输出最后结果。把上面每个步骤用不同的方法来实现。
	如果是面向对象的设计思想来解决问题。面向对象的设计则是从另外的思路来解决问题，面向对象是以功能来划分问题，而不是步骤。
		整个五子棋可以分为1、黑白双方，这两方的行为是一模一样的，2、棋盘系统，负责绘制画面，3、规则系统，负责判定诸如犯规、输赢等。
		第一类对象（玩家对象）负责接受用户输入，并告知第二类对象（棋盘对象）棋子布局的变化，棋盘对象接收到了棋子的变化就要负责在屏幕上面显示出这种变化，同时利用第三类对象（规则系统）来对棋局进行判定。
	同样是绘制棋局，这样的行为在面向过程的设计中分散在了多个步骤中，很可能出现不同的绘制版本，因为通常设计人员会考虑到实际情况进行各种各样的简化。而面向对象的设计中，绘图只可能在棋盘对象中出现，从而保证了绘图的统一。

5.服务器模型
	服务器模型大体分为三种：循环模型、并发模型及IO复用模型
	①循环模型：循环服务器指的是对客户端的请求和连接，服务器处理完一个之后再处理另一个，即串行处理客户端的请求。循环服务器又叫迭代服务器。循环服务器常用于UDP服务程序。	    
	②并发模式:
		   多进程并发模式：如果没有客户端来建立连接，择会阻塞在accept处。一旦某个客户端连接建立起来，则立即开启一个新的进程来处理与这个客户的数据交互。
		   多线程并发模型：在多进程并发模型中，每一个客户端连接开启fork一个进程，虽然linux中引入了写实拷贝机制，大大降低了fork一个子进程的消耗，但若客户端连接较大，则系统依然将不堪负重。
			              通过多线程(或线程池)并发模型，可以在一定程度上改善这一问题。
	③IO多路复用模型（select poll epoll实现）：
		IO多路复用：实现一个进程可以监视多个文件句柄；一旦有个文件句柄就绪，就能通知应用程序执行响应的读写操作，没有事件时，将会阻塞，让出CPU。多路指的是网络连接，复用指的是同一个进程
		实现：采用单线程通过select、poll、epoll等系统调用监控文件描述符，
		select：
			优点：跨平台
			缺点：单进程打开文件描述符有限，
			          每次调用select，都需要把文件描述符集合从用户态拷贝到内核态，开销大
			          select是通过轮询所有的文件描述符， 检测满足条件的fd，需要自己添加业务逻辑提高效率，编码难度提高
		poll：
			优点：突破了文件描述符限制；
			         自带数组结构，可以将监听事件与返回事件集合分离
			缺点：不能跨平台
			          每次调用poll，都需要把文件描述符集合从用户态拷贝到内核态，开销大
			          检测满足条件的fd，需要自己天剑业务逻辑提高效率，编码难度提高
		epoll：		
			优点：突破文件描述符限制，
			缺点：不支持跨平台
			水平触发：只要fd的接收缓冲区有数据，就会触发epoll_wait返回
			边沿触发：高效模式，只有由新的数据流入才会触发，无论缓冲区是否有数据，“非阻塞’

6.c++中重载和覆盖的区别
	1.重载：在同一个类中，函数名相同，参数列表不同
	2.重写：子类重新定义父类中有相同名称参数的虚函数，主要是在继承关系中出现的。被重写的函数必须是虚函数
	3.重定义（隐藏）：子类重新定义父类中有相同名称的非虚函数，参数列表可以相同也可以不同，会覆盖其父类的方法，未体现多态
		如果派生类和基类的函数名相同，但是参数不同，此时，不管有没有virtual，基类的函数都会隐藏
		如果派生类和基类的函数同名，并且参数也相同，但是基类函数没有virtual关键字，此时，基类的函数被隐藏，如果有virtual就是重写了 


8.HTTP、TCP、UDP的区别；
	TCP：面向连接的、可靠的数据包传输。对于不稳定的网络层，采取完全弥补的通信方式，即丢包重传
		优点：稳定（数据流量、传输速度、数据传输顺序）
		缺点：传输速度慢、效率低、开销大
		使用场景：对数据完整性要求较高、不追求效率，比如：文件传输、大数据传输
	UDP：无连接的、不可靠的数据报传输。对于不稳定的网络层，采取完全不弥补的通信方式，默认还原网络状态
		优点：传输速度快、效率高、开销小
		缺点：不稳定（数据流量、速度、顺序）
		使用场景：对实时性要求较高的场合。稳定性其次。比如：视频电话、大型游戏
	区别总结：
		1.tcp是面向连接、保证可靠性的协议
		2.udp是无连接的，不能保证可靠性的连接
		3.tcp有超时重传、滑动窗口机制、确认和应答机制
		4.tcp是面向字节流的传输，不认为消息是一条一条的，数据包之间没有边界，会出现粘包问题，udp数据包是独立的，不会有粘包现象
	粘包：
		什么是粘包：
			发送端为了将多个发送接收端的数据包，更加高效的发送给接收端，于是采用了优化算法，将多次间隔较小，数据量较小的数据，合并成
			一个数据量较大的数据包，然后进行封包。从接收缓冲区看，后一包的数据头紧接着前一包的数据尾。
		出现原因：
			发送方原因：优化算法可能造成粘包
			接收方原因：如果TCP接收数据包到缓存区的速度比应用程序从缓存中读取数据的速度快，多个数据包就会缓存，应用程序就可能读到一个首尾相接黏在一起的数据包
		什么时候需要处理：若多个数据包毫不相干，需要处理
		处理方法：
			1.发送方：关闭优化算法，使用TCP_NODELAY
			2.接收方：将问题交给应用层，通过循环处理，应用程序从缓存区读分组时，读完一条数据，就循环读取下一条，直至所有数据都被处理完
				发送数据的时候定长发送
				尾部标记序列，在每个发送的数据包尾部设置一个特殊的字节序列，用来标识数据包尾部
				头部标记分布接收：定义一个用户报头，在报头标记注明每次发送数据包的大小。接收方每次接收时先以报头的size进行数据读取，得到数据的大小，然后读取数据，就可以了，
						这样一来，每个数据包要先封装一个报头，在封装数据，接收方分两次接收一个数据包，根据报头大小第二次才接受数据内容
	HTTP:应用层协议，超文本传输协议
	      	超文本：不仅包含文本，还包含图片、音频、视频、超链接等
	
	        

	
10.双向链表的逆序
	typedef struct node
               {
            	       ElemType data;
                       struct node *prior
                       struct node *next;
        	}list;
	①不带头节点
		list* reverselist(list *head)
		{		
		        if(head == NULL || head->next == NULL)   //head->next为空，说明只有一个节点
			return head;
		        list *p1= head,*p2 = p1->next,p3=NULL;
		        p1->next = NULL;
		        
		        while(p2 != NULL)
		        {
			p3 = p2->next;     //保存当前节点的下一个节点
			p2->next = p1;     //改变当前节点的next，指向它的前一个节点
			p1->prior = p2;    //改变前一个节点的prior，指向它的下一个节点
			p1 = p2;               //指针移到下一个节点
			p2 = p3; 
		        }
		        head = p1;
		        return head;
		}
	②带头节点
		list *reverselist(list *head)
		{
		            if(head == NULL || head->next == NULL)    //head为空，则是链表不存在，head->next为空，说明链表为空
			return head;
		           list *p1= head->next,*p2 = p1->next,p3=NULL;
		           p1->next = NULL;  
		           while(p2 != NULL)
		           {
			p3 = p2->next;
			p2->next = p1;
			p1->prior=p2;
			p1=p2;
			p2=p3;
		            }             
		            head->next = p1;      //恢复头节点
		            p1->prior->head;
		}
11.二分法
	①在有序数组(有小到大)中查找指定元素
	int search(int *arr,int target,int len)
	{
	      int mid = 0,first = 0,last =len-1;
	      while(first <= last)
	      {
		mid  = (first+last)/2;
	   	if(arr[mid] > target)
		       last = mid -1;
		if(arr[mid] < target)
		       first = mid+1;
		else 
		       retrun mid;
	      }
	      return -1;
	}
	

	
15.udp如何做可靠的连接，缺点，怎么解决这个问题
	1.给数据包增加序号，保证单次通信的多个数据包之间有序
	2.应用层增加校验机制，如接收方得到的校验码和发送方提供的校验码不一致，则丢弃该数据包请求重发
	3,应用层增加确认机制，如果发送方没有在规定时间内收到应答方的应答包，则进行重发
16.gdb coredump 是什么
	当程序运行过程中检测到程序异常退出时（通过信号的方式通知目标进程响应的错误信息，常见信号有SIGBUS SIGSEGV），系统把程序当前内存状况存储在一个core文件中，叫做coredump，
	1.ulimit -a：查看core file 大小，若为0，则默认不使用coredump
	2.设置coredump文件大小：ulimit -c unlimited不限制大小
			          永久生效：修改配置文件/etc/profile  添加 ulimit -c 大小
	3.coredump文件存储位置：默认和可执行程序在同一目录
	4.gdb查看coredump文件
		定位出错误位置
		
17.写一个算法，一个数组得到两个最大数(不用排序)
	int main()
	{
	      int a[10];
	      int i,j;
    	      printf("请输入数组元素:");
	     for(i=0;i<10;++i)
		scanf("%d",&a[i]);
	     int max1 = a[0];
	     int max2 = a[0];
	     for(i = 0; i< 10; ++i)
	     {
		if(max1 <a[i])
		    max1 = a[i];
	     }
	     for(j=0;j<10;++j)
	    {
		if(a[j] > max2 && a[j] < max1)
		       max2 = a[j];
	     }
	     printf("max1 = %d,aecondmax = %d\n",max1,max2);
	     return 0;
	}
18.回调函数怎么使用，回调函数意义
	使用：回调函数也是函数，它具有函数的所有特征，它可以有参数和返回值。单独给出一个函数是看不出来它是不是回调函数的。
	          回调函数区别于普通函数在于它的调用方式。只有当某个函数（更确切的说是函数的指针）被作为参数，被另一个函数调用时，它才是回调函数。
	意义：所谓回调函数就是把函数当作参数使用。目的是使程序更加普适。

19.写一个链表中找最小值
	LinkList select_Min(LinkList L)
	{
	       assert(L->next == NULL)   //判断链表是否为空
		retrun NULL;
	       LinkList *p,*minP;
	       p = L->next;
	       minP = p;
	       while(p != NULL)
	       {
		if(minP->data > p->data)
		       minP = p;
		p=p->next;
	       }
	       return minP;    
	}
20.写一个程序从2000年到现在有多少天
	int  count_day(int year)
	{
	      int sum = 0;
	      int day;
	      for(i = 2000; i < year; ++i)
	      {
		if((i%4 ==0 && i %100 != 0) || (i %400 == 0) )
		       day = 365;
		else
	  	       day = 366;
	      }
	      sum += day;
	      retrurn sum;
	}
21.宏定义跟const的区别
	const 定义的是变量不是常量，只是这个变量的值不允许改变是常变量！带有类型。编译运行的时候起作用存在类型检查。
	define 定义的是不带类型的常数，只进行简单的字符替换。在预编译的时候起作用，不存在类型检查。
	区别：①编译器处理方式不同：宏定义是在预处理阶段展开，const 变量是在编译运行阶段使用
	          ②类型和安全检查不同：#define 宏没有类型，不做任何类型检查，仅仅是展开。
				const 常量有具体的类型，在编译阶段会执行类型检查。
	          ③存储方式不同：define宏仅仅是展开，有多少地方使用，就展开多少次，不会分配内存。（宏定义不分配内存，变量定义分配内存。）
			     const常量会在内存中分配(可以是堆中也可以是栈中)。
	          ④const可以保护被修饰的东西，防止意外的修改，增强程序的健壮性。

22.内核态和用户态	
	区别：在用户空间下执行，我们把此时运行的程序的这种状态称为用户态，而当这段程序执行在内核的空间执行时，这种状态称为内核态。
  	          当一个任务(进程)执行系统调用而陷入内核代码中执行时，我们就称进程处于内核状态。此时处理器处于特权级最高的(0级)内核代码。当进程处于内核态时，执行的内核代码会使用当前的内核栈。每个进程都有自己的内核栈。
	          当进程在执行用户自己的代码时，则称其处于用户态。即此时处理器在特权级最低的用户代码中运行。当正在执行用户程序而突然中断时，此时用户程序也可以象征性地处于进程的内核态。因为中断处理程序将使用当前进程的内核态。

23.什么是CS模型和BS模型， 他们的区别？
	cs优点：
		cs架构的界面和操作可以很丰富
		安全性能很容易保证
		响应速度快
	cs缺点：
		维护成本高
		用户群固定，程序需要安装才可以使用
	bs优点
		具有分布式特点，可以随时进行查询、浏览等业务
		业务扩展简单，增加网页即可增加服务器功能
		维护简单方便
		开发简单，共享性强
	缺点：
		速度和安全性

24.什么是大小端及用程序验证

25.memmove程序思想
	strncpy考虑内存重叠的实现（使用strncpy时，最好手动添加‘\0’在结尾）
	char *my_strncpy(void *dst, const void *src,int len)
	{
	        assert(src!= NULL && dst != NULL);
	        char *res = (char *)dst;
	        int offset = 0;
	        char *tmp = NULL;
	        if(strlen(src) < len)       //src 小于len
	       {
		offset = len - strlen(src);
		len = strlen(src);
                       }
	       if(dst >= src && dst <=(src +len-1))
	       {
		dst = dst +len -1;
	 	src= src+ len -1;
		tmp = dst + 1;              是否要加1
		while(len--)
		{
		        *dst-- = *src--;
		}
 	       }
	       else
	       {
		while (len--)
		       *dst++ = *src ++;
		tmp = dst;
	       }
	       while(offset--)
	       {
		*tmp++ = '\0';
	       }
	       return res;
	}
	memcpy：没有考虑内存重叠问题
	memmove：内存重叠时仍然可以正常执行
	void *my_memmove(void *dest,const void *src,size_t n)
	{
	     assert(dest != NULL && src != NULL)；
	     char *p_dest = (char *)dest;
	     const char *p_dest = (const char *)dest;
	     int i = 0;
	     if(p_dst <= p_src || p_dst >= (p_src + n))      //不重叠，从后向前拷贝
	     {
		while(n--)
		{
		       *p_dst ++ = * p_src ++;
		}	
	     }
	     else     //重叠，从后向前拷贝
	     {
		p_dst = (char *)dst +n -1;
		p_src = (char *)src + n - 1;
		while(n--)
		{
		       *p_dst -- = *p_src -- ;
		}
	     }
	     return dest;
	}
	
26.二叉树遍历

27.中断上下文、中断的上下部

28.new与malloc的区别
	new和delete是c++关键字，需要编译器支持；malloc和free是库函数，需要头文件支持
	new和detele在对象创建的时候自动执行构造函数，在对象销毁的时候自动执行析构函数
	new返回指定类型的指针，并可以自动计算出所需空间大小，malloc必须用户指定大小，并且默认返回void *，必须强制转换为实际类型指针

29.memcyp与strcpy的区别
	参数不同
	执行效率不同
	结果不同
30.ftp和tftp
	ftp协议：文件传出协议（TCP）
		ftp使用两个端口，21（服务器的命令端口）  20是（主动模式的数据连接）
			两个TCP连接，一个是控制层面的连接，一个是数据层面的连接
		主动模式：第二信道的tcp连接由服务器主动发起
			1.客户端主动找服务器建立第一信道，服务器的端口为21
			2.客户端给服务器发送一个数据包（port命令），告诉服务器客户端的地址结构信息-------A B C D E F（ABCD为客户端ip地址，E*256+F为客户端端口号）
			3.服务器主动发起第二信道的tcp连接

		被动模式：第二信道的tcp连接由客户端主动发起
			1.客户端主动找服务器建立第一信道，服务器的端口为21
			2.服务器给客户端发送一个数据包（pasv命令）-------A B C D E F（ABCD为服务器ip地址，E*256+F为服务器端口号）
			3.客户端主动发起第二信道的tcp连接
		常用命令：
			登录ftp服务器：ftp ip(服务器)  然后输入用户名和 密码
			查看ftp服务器上的文件：dir：显示服务器目录和文件列表
				  	      ls：显示服务器目录和文件列表
					      cd：进入服务器指定目录
					     lcd：进入本地客户端指定的目录
			下载文件：传输方式有二进制和ascii两种
				type：查看当前文件传输方式
				ascii：设定文件传输方式为ascii
				binary：设定文件传输方式为二进制方式
				get/recv：下载单个文件 get filename [newname]（filename为服务器上的文件名，newname为保存在本地的文件名）
				mget：下载多个文件
			长传文件：
				put/send：长传单个文件put filename [newname]（filename为本地的文件名，newname为服务器的文件名）
				mput：上传多个文件
			结束并退出
				bye：结合和服务器的ftp并推出ftp环境
			其他命令：
				pwd：查看ftp服务器的当前工作目录
				passive：主动和被动模式切换
				delete filename：删除服务器上一个文件
				mdelete：删除多个文件
				mkdir：在服务器上创建目录
	tftp：简单文件传输协议（UDP）
		tftp的服务器端口号69，仅支持文件上传和下载功能，支持丢包重传
		tftp传输是由客户端发起：
			文件下载：客户端发送读请求给服务器作为开始
				服务器发送数据报文（块编号1）给客户端 ，每次传输512字节
				客户端发送确认报文（ACK=1）给服务器
				。。。。。。。
				最后一次传输小于512字节，说明传输终止
			文件上传：客户端发送写请求给服务器
				服务器发送确认报文（ACK=0）给客户端   
				客户端发送数据报文（块编号1）给服务器
				服务器发送确认报文（ACK=1）给客户端
		

31.内核移植和裁剪
	嵌入式系统包含硬件子系统和软件子系统
		软件子系统包含BootLoader、linux内核、文件系统、应用程序
	系统启动流程
		BootLoader->linux kernel(zImage)->rootfs(init)-->application
	系统移植的四部分：
		1.搭建交叉编译环境
		2.bootloader的选择和移植
		3.kernel的配置、编译移植和测试
		4.根文件系统的制作
	移植的基本步骤：
		1.确定目标机、主机的连接方式（串口、usb串行通信、TCP/IP、debug/jtag调试接口）
			【pc-开发板】环境搭建：主机程序开发，开发板执行显示结果
			 主句的数据传递如何到开发板：	包括uboot、kernel
				串口：普通文件，用来打印调试信息   
				网络接口：TFTP	
				调试：挂载（NFS）
			
		2.安装交叉编译环境（pc机的架构为x86,和ARM不兼容）
			为什么要交叉编译器？
				主机的架构是x86的cpu，单片机（目标机）是arm架构的cpu，主句和目标机不是一个平台，称为交叉。交叉编译器就是在一个平台上编译出能运行在另一个体系结构不同的平台上的程序。
				file命令：file 可执行程序，可以告诉我们可执行程序工作的平台的架构
			安装交叉编译器：直接安装
				解压缩：~/tiny210_porting/toolchain/arm-linux-gcc-4.5.1-v6-vfp-20120301.tar.gz
					sudo tar -zxvf arm-linux-gcc-4.5.1-v6-vfp-20120301.tar.gz -C /(这里解压到根文件，即/opt/FriendlyARM)
						/opt/FriendlyARM下有bin：交叉编译器的可执行命令
								    lib：arm-none-linux-gnueabi-gcc
								    arm-none-linux-gnueabi-：
								    share：
			使用方法：
				1. 简单方法：
					在/etc/environment下添加PATH环境变量
					arm-none-linux-gnueabi-gcc 1.c -o build
			  	2.使用绝对路径：
					/opt/FriendlyARM/bin/arm-none-linux-gnueabi-gcc 1.c -o build
								     
		3.搭建主句和目标机数据传输通道（TFTP、NFS）
		4.编译三大子系统
			uboot：.bin文件烧写到板子的flash或者sd卡中
				作用：初
			kernel：
				1.解压
				2.修改Makefile：进入解压后的linux-3.3.6后，打开Makefile，指定arm架构、交叉编译器位置修改为
						ARCH ? = arm
						CROSS_COMPLIE=/opt/FriendARM/toolchain/4.4.3/bin/arm-linux
				3.修改机器码：
					linux-3.3.4/arch/arm/tools目录下的mach-types 修改机器码，因为uboot和内核时候通过机器码以及名字匹配的
				4.cp linux-3.3.4/arch/arm/mach-smdkv210.c   linux-3.3.4/arch/arm/smdkv210.c 
					修改文件/smdkv210.c中的机器名字SMDK210为MINI210和uboot中的保持一致
				5.编译内核：cp linux-3.3.4/arch/arm/s5p210_defconfig .config 把开发板的配置文件拷贝到linux-3.3.4目录下的.config文件
					通过命令make menuconfig进入配置界面进行配置
						general setup->cross-conplier toolprefix输入编译器路径
						system types->
						boot option->
					编译内核：make uIamge
			让编译好的内核在开发板上运行：
				1.尽力tftp服务器
				2.启动编译好的内核：cp linux-3.3.5/arch/arm/boot/uImage tftpboot
					将编译好的内核拷贝到tftp服务器的根目录下
				3.将烧写好了uboot.bin的sd卡，插到开发板上
				4.将开发板可主句连接，ping  192.168.186.30(主机ip) 
				5.在开饭输入 tftp uImage，把tftp服务器的uImage文件拷贝到开发板
				6.bootm启动内核 
			根文件系统：
				1.制作根文件系统
				2.挂载根文件系统：NFS挂载根文件系统，有利于开发过程中的同步
					a.make menuconfig :file system->network file system->root file system on NFS,保存退出，重新编译make uImage，并拷贝到tftp服务器目录下
					b.设置nfs环境变量
			
		5.烧写测试
	
32.ARP协议
	简单地来说，ARP协议就是地址解析协议。通过目的ip地址而获取目的mac地址的过程
	①网络设备在什么情况下会发送ARP request？
		源设备在发送数据给目的设备前，会首先查看自身的ARP缓存，查找ARP缓存中是否存在目的设备的IP地址和MAC地址的映射。
		如果存在则直接使用，如果不存在则会发送ARP request。
	②每一台主机都设有一个ARP高速缓存（ARP cache）。里面有本局域网上的各主机和路由器的IP地址到硬件地址的映射表，这些都是该主机目前知道的一些地址。那么主机怎样知道这些地址呢？
		当主机A要向本局域网上的某台主机B发送IP数据报时，就先在其ARP高速缓存中查看有无主机B的IP地址，如果有，就在ARP高速缓存中查出其对应的硬件地址，
		再把这个硬件地址写入MAC帧，然后通过局域网把该MAC帧发往此硬件地址。
		也有可能查不到主机B的IP地址的项目。这可能是主机B才入网，也可能主机A刚刚加电，其高速缓存还是空的，在这种情况下，主机A就自动运行ARP，
		然后按下面的步骤找出主机B的硬件地址。
		      1） ARP进程在本局域网上广播发送一个ARP请求分组。
	   	      2） 在本局域网 上的所有主机上运行的ARP进程都收到此ARP请求分组。
 		      3） 主机B的IP地址与ARP请求分组中要查询的IP地址一致，就收下这个ARP请求分组，并向主机A发送ARP响应分组，同时在这个ARP响应分组中写入自己的硬件地址。
		     4）主机A收到主机B的ARP响应分组后，就在其ARP高速缓存中写入主机B的IP地址到硬件地址的映射。
		     ARP对保存在高速缓存中的每一个映射地址项目都设置生存时间（如，10~20分钟）。凡超过生存时间的项目就从高速缓存中删除掉。
	③ARP请求时解决同一个局域网上的主机或路由器的IP地址和硬件地址的映射问题，如果所要找的主机和源主机不在同一个局域网上，看上图有H1的那个图，主机H1就无法解析出另一个局域网上主机H2的硬件地址。
	   主机H1发送给H2数据报首先需要通过与主机H1连接在同一个局域网上的路由器R1来转发。因此主机H1这时需要把路由器R1的IP地址IP3解析为硬件地址HA3，以便能够把IP数据报传送到路由器R1，以后，
	   R1从转发表找到下一跳路由器R2，同时使用ARP解析出R2的硬件地址HA5。于是IP数据报按照硬件地址HAA5转发到路由器R2。路由器R2转发这个IP数据报时用类似方法解析出目的主机H2的硬件地址HA2，使IP数据报最终交付给主机H2。
		1） 发送方是主机（如H1），要把 IP 数据报发送到本网络上的另一个主机（如H2）。这时H1发送 ARP 请求分组（在网1上广播），找到目的主机H2的硬件地址。 
		2） 发送方是主机（如H1），要把 IP 数据报发送到另一个网络上的一个主机（如H3或H4）。这时H1发送 ARP请求分组（在网1上广播）， 找到网1上的一个路由器R1的硬件地址。剩下的工作由这个路由器R1来完成。R1要做的事情是下面的（3）（4） 
		3） 发送方是路由器（如R1），要把 IP 数据报转发到与R1连接在同一个网络（网2）上的一个主机（如H3）。这时R1发送ARP请求分组（在网2上广播）， 找到目的主机H3的硬件地址。 
		4） 发送方是路由器（如R2），要把 IP 数据报转发到网3上的一个主机（如H4）。H4与R1不是连接在同一个网络上，这时R1发送ARP请求分组（在网2上广播），找到连接在网2上的一个路由器R2的硬件地址。剩下的工作由这个路由器R2来完成。

	有了ip地址为什么还需要arp协议
		arp协议工作在局域网内部那一层面
		1.ip地址是逻辑地址寻址，工作在网络层，具有全网范围内的寻址能力，可以快速定位目标地址所在的网络
		2.mac地址是物理地址寻址，工作在数据链路层，要将数据包发送给对方必须知道对方的mac地址，因为主机的以太网网卡只能识别mac地址
33.字符设备驱动框架
	1.实现模块加载和卸载入口函数
	2.在模块加载入口函数中	
		a.为设备对象申请空间
		b.申请设备号，用于区分不同的字符设备
		c.创建设备节点文件，为用户提供一个可操作的文件接口
		d.硬件的初始化
			1.地址的映射ioremap			
			2.中断的申请
			3.实现硬件寄存器的初始化
		e.实现file_operation结构体

34.简述TCP的三次握手、四次挥手的过程
	建立连接的过程：
	1）客户端发送一个带SYN标志的TCP报文到服务器，这是三次握手过程中的段1
	2）服务器端回应客户端，是三次握手中的第2个报文段，同时带ACK标志和SYN标志。它表示对刚才客户端SYN的回应；同时又发送SYN给客户端，询问客户端是否准备好进行数据通讯。
	3）客户必须再次回应服务器端一个ACK报文，这是报文段3。
	断开连接的过程：
	由于TCP连接是全双工的，因此每个方向都必须单独进行关闭。这原则是当一方完成它的数据发送任务后就能发送一个FIN来终止这个方向的连接。
	收到一个 FIN只意味着这一方向上没有数据流动，一个TCP连接在收到一个FIN后仍能发送数据。首先进行关闭的一方将执行主动关闭，而另一方执行被动关闭。
	1）客户端发出FIN位表示关闭连接的请求。
	2）服务器发出ACK,应答客户端的关闭连接请求。
	3）服务器发出FIN位，向客户端发送关闭连接请求。
	4）客户端发出ACK,应答服务器的关闭连接请求。
	建立连接的过程是三方握手，而关闭连接通常需要4个段，服务器的应答和关闭连接请求通常不合并在一个段中，因为有连接半关闭的情况，这种情况下客户端关闭连接之后就不能再发送数据给服务器了，但是服务器还可以发送数据给客户端，直到服务器也关闭连接为止。
35.什么是滑动窗口
	滑动窗口通俗来讲就是一种流量控制技术
	它本质上是描述接收方的TCP数 据报缓冲区大小的数据，发送方根据这个数据来计算自己最多能发送多长的数据，如果发送方收到接收方的窗口大小为0的TCP数据报，
	那么发送方将停止发送数据，等到接收方发送窗口大小不为0的数据报的到来。避免如果发送端发送的速度较快，接收端接收到数据后处理的速度较慢，而接收缓冲区的大小是固定的，就会丢失数据。

36.什么是半关闭
	当TCP链接中A发送FIN请求关闭，B端回应ACK后（A端进入FIN_WAIT_2状态），B没有立即发送FIN给A时，A方处在半链接状态，此时A可以接收B发送的数据，但是A已不能再向B发送数据。
37.2MSL存在的理由（maximu segment Lifetime最大报文生存时间30-60s，msl即单向传输tcp报文的最长时间）
	一定出现在主动关闭端，因为最后一个ack是主动方发送的
	1）让四次挥手关闭流程更加可靠	
		4次握手的最后一个ACK是是由主动关闭方发送出去的，若这个ACK丢失，被动关闭方会再次发一个FIN过来。若主动关闭方能够保持一个2MSL的TIME_WAIT状态，
		则有更大的机会让丢失的ACK被再次发送出去。
	2）处理延迟的重复报文，这主要是为了避免前后两个使用相同连接中的前一个连接的报文到干扰后一个连接。
38.路由器和交换机 集线器
	集线器：
		定义：将网线集结起来的作用，实现最初级的网络互通，集线器是通过网线直接传送数据的，我们说他工作在物理层
		集线器的问题：由于集线器和每台设备都相连，他不能分辨出信息时给谁发送的，只能广泛的广播出去，A在发消息给C的时候，其他主机不能发消息，否则信息间会产生碰撞，引发错误，我们称各设备处于同一冲突域
	交换机：
		定义：根据网口的mac地址传送信息，这比网线直接传送多了一个步骤，即交换机工作在数据链路层，交换机解决了冲突问题，实现了任意两台电脑之间的互联，
	路由器：
		是互联网的枢纽，是连接英特网中各局域网、广域网的设备，它会根据信道的情况自动选择和设定路由，以最佳路径，按前后顺序发送数据。
		作用在OSI模型的第三层，提供了路由与转发两种重要机制
		路由：路由器控制层面的工作，决定数据包从来源端到目的端所经过的路由路径
		转发：路由器数据层面的工作，将路由器输入端的数据包移送至适当的路由器输出端（在路由器内部进行）
		路由器是一种具有多个输入端口和多个输出端口的专用计算机，其任务是转发分组。也就是说，将路由器某个输入端口收到的分组，
		         按照分组要去的目的地，把该分组从路由器的某个合适的输出端口转发给下一跳的路由器。下一跳的路由器也按照这种方法处理分组，直到该分组到达终点为止。
	区别：
		1）工作层次不同：最初的交换机工作在OSI开放式系统互联模型的数据链路层，也就是第二层，而路由器则工作在OSI模型的网络层，就是第三层。
		2）数据的转发对象不同：交换机是根据MAC地址转发数据帧，而路由器则是根据IP地址来转发IP数据报/分组。数据帧是在IP数据包/分组的基础上封装了帧头（源MAC和目的MAC等）和帧尾（CRC校验码）。
		3）”分工“不同：交换机主要是用于组建局域网，而路由器则是负责让主机连接外网。
		4）冲突域和广播域：交换机分割冲突域，但是不分割广播域，而路由器分割广播域。
			冲突域是基于第一层（物理层）
			广播域是基于第二层（数据链路层）
	集线器;
		
39多路io  .select和epoll poll区别和缺点
	select缺点 ：①监听上限受文件描述符限制，默认最大为1024
	                    ②
	select优点：跨平台
	poll缺点：不能跨平台，window不支持，无法直接定位满足监听监听事件的文件描述符，编码难度大。
	poll优点：自带数组结构，可以将监听事件和返回事件集合分离，可以拓展监听上限，超出1024限制
	epoll缺点：不能跨平台，只支持linux，突破1024文件描述符
	epoll优点：高效
40.select的缺点，epllo是怎么改进select的这些确定的
	select缺点：
		1.select支持的文件描述符数量收到限制，最大1024
		2.每次调用select，都需要把fd从内核态拷贝到用户态，开销大
		3.每次调用select，内核需要遍历传进来的所有fd，
	epoll解决方案：	
		1.epoll所监听的fd，不受限制文件描述符限制
		2.epoll的解决方案在于epoll_ctl函数，每次注册新的事件到epoll具备中，会把所有的fd拷贝到内核，而不是在epoll_wait的时候重复拷贝，epoll保证每个fd整个过程只拷贝一次
		3.epoll只会对准备就绪的fd进行操作，而不是线性扫描所有fd的集合，这是因为内核实现中epoll是根据每个fd上面的回调函数实现的，只有就绪的fd才会调用回调函数，将就绪的fd加入就绪链表
	
41.如何设置将socket成非阻塞模式
	struct epoll_event event；
	event.events = EPOLLIN|EPOLLET
	int flag= fcntl(cfd, FD_FETFL);
	flag |= O_NONBLOCK;
	fcntl(cfd, FD_SETFL, flag)
42.如何设置socket的属性
	setsockopt(fd,level,optnamae,optval,optlen)设置socket属性
	比如：端口复用、接收超时、发送超时、缓冲区大小设置
	getsockop,获取socket属性
	
43.gdb调试，bt命令，如何处理段错误，怎么设置断点
	段错误：程序访问了一端不可访问的内存
	产生原因：解引用空指针、栈溢出、使用野指针、访问不可访问的内存空间、写一个只读区域等
	处理方法：gdb coredump

44.在建立socket之后为什么send和write都可以用，写到文件里的东西是怎么到网络通信的
	建立网络通信后，可以将socket对应的fd当做文件描述符使用，对应的send、write函数就都可以用了

45.字符设备和块设备区别
	字符设备：按照字节流的方式被有序访问的设备，比如串口、键盘、鼠标
	块设备：系统中能够随机访问（不需要按顺序）访问固定大小数据片的设备，比如，硬盘、闪存
	区别：是否可以被随机访问，即能否在访问设备的时候随意地从一个位置跳到另一个位置

46.交叉开发的目的，流程；内核的启动流程
	内核启动流程：系统刚上电时，处理器会执行bootloader，初始化处理器和外设，然后调用linux内核，linux内核在完成系统的初始化后需要挂载某个文件系统作为根文件系统，
		       然后加载必要的内核模块，启动应用程序
	bootloder：初始化ram，因为内核一般在ram中运行、
		    初始化串口，串口用于在启动过程打印调试信息，便于了解linux的启动过程
		    初始化硬件：网卡、时钟、
		    设置linux内核启动参数
		    
47.线程池
	定义：本质就是一个可以容纳多个线程的容器，其中线程可以反复使用，省去了频繁创建线程对象的操作
	优点：
		1.降低资源消耗：减少了创建和销毁线程的次数，每个线程都可重复使用，
		2.提高响应速度：当任务到达时，无需等到线程创建就能立即执行
		3.提高线程的可管理性，可以随时根据系统的承受能力，调整线程池中工作线程的数目，
	为什么使用线程池，而不是直接创建
		当频繁使用pthread_create创建多个线程，不仅消耗系统资源，还会降低系统稳定性
	核心参数：
		最大线程数
		核心线程数
		任务队列
	常见的线程池
		单线程化的线程池、
		定长线程池
		可缓存的线程池
	对线程池的操作
	        main:
		threadpool_create：创建线程池
		threadpool_add：在线程池中添加任务,默认添加一个任务，线程就借助回调函数执行一个任务
		销毁线程池
	

48.内存5大分区
	1、栈区(stack): —由编译器自动分配释放，存放函数的参数值，局部变量的值等。
	2、堆区(heap): 一般由程序员分配释放，若程序员不释放，程序结束时由系统释放。
	3、全局区(静态区,static): 全局变量和静态变量的存储是放在一块的，初始化的全局变量和静态变量在一块区域，未初始化的全局变量和未初始化的静态变量在相邻的另一块区域.bss。程序结束后由系统释放。
	                      在编译阶段(而非运行时)就分配空间,可读可写
	4、文字常量区: 常量字符串就是放在这里的。程序结束后由系统释放。
	5、程序代码区: 存放函数体的二进制代码。

49.阻塞和非阻塞？

50.编译时动态库和静态库
	动态库：库的代码不会编译进程序中，所以动态库编译的程序比较小
	             由动态库编译的程序依赖于系统的环境变量有没有这个库，没有则运行不了
	静态：库的整个代码编译进程序，程序比较大
	
51.tcp能不能只进行2次握手而不是三次，为什么
	3次握手过程：
		服务器端新建套接字，绑定地址结构信后，开始监听，进入listen状态，客户端新建套接字后，调用conne函数发送连接请求SYN，并进入SYN_SEND状态，等待服务器确认
		服务器一端一旦监听到有连接，会向客户端发送SYN和ACK应答，进入SYN_RCVD状态，
		客户端收到SYN+ACK后，发送ACK应答给服务器，并进入ESTABLISHED状态，开始读写数据，服务器收到ACK后，也进入ESTABLISHED状态，进行数据读写。	
	2次不安全，四次没必要
		tcp通信需要确认双方都具有数据收发能力，得到ACK响应则认为对方具有收发能力
		第一次握手是客户端发送SYN，服务器接收，服务器得出客户端发送能力、服务器端接收能力正常
		第二次握手服务器发syn+ack,客户端接收，客户端得出客户端发送、接受能力正常、服务器端的发送能力正常，但是此时服务器并不能确定客户端的接收能力是否正常
		第三次握手客户端客户端发送ack，服务器确认客户端的发送接收能力正常，服务器端自己的接收发送能力正常
	3次握手可以携带数据吗
	tcp的3次握手失败了，服务器端会如何处理
		失败原因有两种：
			1.服务器端没有收到SYN，则什么都不做
			2.服务器端回复了SYN+ACK，但一直没有收到ACK响应，则超时后就会发送RST重置连接报文，释放资源
	什么是半连接队列
		服务器第一次收到客户端的SYN后，就会处于SYN_RCVD状态，此时双方还没有完全建立连接，服务器会把这种状态下的连接请求放在一个队列中，成为半连接队列。
		全连接队列，就是已经完成3次握手，建立起来连接的就会放在全连接队列
	四次握手	
		客户端主动调用close函数，向服务器发送结束报文FIN，同时进入FIN_WAIT1状态
		服务器收到FIN后，服务器会返回确认报文ACK进入CLOSE_WAIT状态。如果此时服务器有数据要发送的话，客户端依然需要接收。客户端收到服务器的ACK应答，进入FIN_WAIT2状态，半连接
		服务器端数据发送完毕后，当服务器调用close关闭连接后时，会向客户端发送结束报文FIN，此时服务器进入LAST_ACKA状态，等待最后一个ACK的到来
		客户端收到服务器的结束报文，进入TIME_WAIT状态，并发送ACK给服务器，服务器收到后，立即进入CLOSED状态，而客户端要等待2msl时长，才会进入CLOSED状态
	为什么不是三次而是四次
		由于TCP是全双工的，主动关闭方发送FIN请求不代表完全断开连接，只能表示主动关闭方不再发送数据了。而接收方可能还要发送数据，，就不能立即关闭服务器端到客户端的数据通道，
		所以就不能将服务器的FIN包给客户端的ACK包合并发送，只能先确认ACK，，等到服务器无需再发送数据包时再发送FIN包，所以需要四次
	TIME_WAIT状态作用，为什么主动关闭方没有直接closed
		如果主动关闭连接方进入CLOSED状态，被动关闭方发送FIN包没有收到ACK确认，超时后就会重传一个FIN包。
		如果客户端没有TIME_WAIT状态直接进入CLOSE的状态释放资源，下次启动新的客户端就有可能使用了和之前客户端相同的地址信息有两个危害，
			第一个是这个刚启动的新客户端绑定地址成功后，就会收到一个重传的FIN包，对连接造成影响
			第二种是如果该客户端向相同服务器发送SYN连接请求，但此时服务器处于LAST_ACK状态，要求收到ACK而不是SYN，因此就会RST重置连接
	为什么是2MSL
		MSL指的是报文在网络中的最大生存时间，在客户端发送对服务器FIN包的确认包ACK后，这个ACK包会有可能到不了，服务器端如果没有接收到ACK，就会重传一个FIN包。所有客户端发送ACK需要留出2MSL的时间（ACK到达服务器时间+
		服务器重发FIN时间）等待确认服务器确实收到了ACK包，也就说客户端若2msl内没有收到服务器重传的fin，就认为服务器收到了客户端发送的ACK包
	一台主机（服务器）大量出现TIME_WAIT的原因，如何处理
		TIME_WAIT是主动关闭连接方的一种状态，一台主机大量出现TIME_WAIT说明这台主机上发起了大量的主动关闭连接
		如果是客户端处于这种状态，问题不大，如果是服务器的话，则有问题
		解决办法：
			开启服务器套接字地址复用选项SO_REUSEADDR来通知内核，如果服务器端口忙，但tcp连接处于TIME_WAIT状态时，可以重用端口
	一台主机大量出现CLOSE_WAIT的原因，如何处理
		CLOSE_WAIT是被动关闭连接方的一种状态，一台主机大量出现CLOSE_WAIT，有可能是被动方主句程序中忘了最后一步断开连接后调用close释放资源。
		解决办法：查代码
	tcp管理中的保活机制（客户端出现故障怎么办）
		tcp通信中，若两端长时间没有数据往来，则这时候每隔一段时间，服务器就会发送一个保活探测数据包，要求客户端进行回复，若连续多次没有收到响应，则认为已经断开。
		长时间默认7200s，每隔一段时间默认75s，连续多次，默认9次，
	
52.gdb如何多线程调试，如何查看线程，如何跟踪线程
	跟踪线程attach  线程号    或者     gdb -p 线程号
	查看线程info thread显示进程当前所有线程   跟踪线程thread  num（info thread得到）
	查看线程执行到哪  bt
	
	
	
53.进程线程间通信：
	线程间通信：线程间的通信目的主要是用于线程同步，所以线程没有像进程通信中的用于数据交换的通信机制。
		①锁机制：包括互斥锁、条件变量、读写锁和自旋锁
		     互斥锁确保同一时间只能有一个线程访问共享资源。当锁被占用时试图对其加锁的线程都进入阻塞状态(释放CPU资源使其由运行状态进入等待状态)。当锁释放时哪个等待线程能获得该锁取决于内核的调度。
		     读写锁当以写模式加锁而处于写状态时任何试图加锁的线程(不论是读或写)都阻塞，当以读状态模式加锁而处于读状态时“读”线程不阻塞，“写”线程阻塞。读模式共享，写模式互斥。
		     条件变量可以以原子的方式阻塞进程，直到某个特定条件为真为止。对条件的测试是在互斥锁的保护下进行的。条件变量始终与互斥锁一起使用。
		      自旋锁上锁受阻时线程不阻塞而是在循环中轮询查看能否获得该锁，没有线程的切换因而没有切换开销，不过对CPU的霸占会导致CPU资源的浪费。 所以自旋锁适用于并行结构(多个处理器)或者适用于锁被持有时间短而不希望在线程切换产生开销的情况
		②信号量机制(Semaphore)
	进程间通信：
		①管道：可用于具有亲缘关系进程间的通信，有名管道克服了管道没有名字的限制
		②信号：用于通知接收进程某个事件已经发生
		③共享内存：最快的进程间通讯的方式，共享内存直接在进程的虚拟地址空间进行操作，不再通过执行进入内核的系统调用来传递彼此的数据
		④套接字
		
		
54.IIc UART SPI的时序图描述
	两种通信方式：
		并行通信：数据各个位同时发送，传输速度快，占用引脚资源多
		串行通信：数据各按位顺序传输，传输速度相对较慢，占用引脚资源少
		             按照数据传输方向分为：
			单工：数据传输只支持数据在一个方向上传输
			半双工：允许数据在两个方向上传输，但，某一时刻，只允许数据在一个方向上传输
			全双工：允许数据同时在两个方向上传输
		             串行通信的通信方式：
			同步通信：带时钟同步信号传输
	 		异步通信：不带时钟同步信号    UART，事先约定好比特率
	UART（通用异步接收发器）：串口 异步通信 全双工     USART（通用同步异步接收发器）
	        主机和从机至少要接三根线，RX，TX和GND.TX用于发送数据，RX用于接受数据（收发不是一根线，所以是全双工方式）。
	        两个设备通过UART通信，那么A设备的RX应该与B设备的TX连接、A设备的TX与B设备的RX连接，
	        如果一方为PC机，一方为单片机。需要将TTL/CMOS（单片机电平）转换为RS232（PC机电平）。因为TTL/CMOS电平范围为0-1.8/2.5/3.3/5V，逻辑上1表示高电平，0表示低电平。RS232的电平范围为-12-12V，-5~ -12V表示高电平，5-12V表示低电平
	        数据协议：串口通信重要参数：起始位、数据位、奇偶校验位、停止位、波特率设置
		数据协议：以PC机一给单片机乙发数据为例（1为高电平，0为低电平）：A.TX to B.RX.刚开始B.RX的端口保持1，当A.TX发来 个0作为起始位告诉乙我要发数据了！然后就开始发数据，发多少呢？通常一次是8位，这个双方事先要用软件设置好.
		第9位可以为奇偶校验位。PC机一般会用串口助手设置，单片机会在UART的驱动中设置。一小帧数据发送完了以后，A.TX给个高电平告诉B.RX我发完了一帧。如果还有数据，就再给个0然后重复上一步。如果双方约定由校验位，还要在发停止位1之前发送个校验位。
	SPI：全双工同步串行总线，
	       SPI工作原理总结：
		①硬件上为4根线：MISO 主设备数据输入，从设备数据输出。MOSI 主设备数据输出，从设备数据输入。SCLK 时钟信号，由主设备产生。CS 从设备片选信号，由主设备控制。
		②主机和从机都有一个串行移位寄存器，主机通过向它的SPI串行移位寄存器写入一个字节来引起一次传输
		③串行移位寄存器通过MOSI信号线将字节传送给从机，从机同时也将自己的串行移位寄存器中的内容通过MISO信号线返回给主机。这样，两个寄存器中的内容就被交换。
		④外设的写操作和读操作是同步完成的。如果只进行写操作，主句只需要忽略收到的字节即可；反之，若主机要读取从机的一个字节，就必须发送一个空字节来引起从机的传输。

	IIC：两线式的半双工串行通信：一个时钟线SCL和一个数据线SDA。只有一根数据线，可发送和接收数据，在cpu和被控IIC设备，IIC设备与IIC设备直接进行双向传输
	        空闲状态：SCL 和 SDA空闲状态默认都为高电平
	        开始信号：当SCL为高电平期间，SDA由高到低的跳变，启动信号是一种电平跳变时序信号，而不是一个电平信号
	        停止信号：当SCL为高电平期间，SDA由低到高的跳变，启动信号是一种电平跳变时序信号，而不是一个电平信号
	        应答信号：发送器每发送一个字节（8位），就在时钟脉冲9期间释放数据线，由接收器反馈一个应答信号。应答信号为低电平时，规定为有效应答位，表示接收器以及成功接收了该字节；
		        应答信号为高电平时，规定为非应答位，表示接收器接收该字节没有成功。对于反馈有效应答ACK的要求是，接收器在第9个时钟脉冲之前的低电平期间将sda拉低，并且确保在改时钟的高电平期间为稳定的低电平。
	        数据的有效性：数据传输时，时钟信号为高电平期间，数据线上的数据必须保持稳定，只有在时钟信号为低电平时，数据线上的电平状态才允许变化。
		  	即数据在SCL的上升沿到来前必须就准备好，并在下降沿到来之前必须保持稳定
	        数据传输：在iic总线上每一个数据都有一个时钟脉冲相对应，数据位的传输是边沿触发

56.内存溢出和内存泄漏
	内存溢出：指的是程序申请内存时，没有足够的内存供申请者使用。
	原因：
		1.以前申请的内存，用完之后没有及时清空，使得不能回收
		2.代码中循环或迭代次数过多
		3.内存中加载的数据量过于庞大，，比如一次从数据库中读取的数据太多
	
57.怎么避免数据库同时被读写
	数据库并发操作：指的是多个用户/进程/线程同时对数据库进行操作
	出现三种情况：
		读、读：不存在问题
		读、写：可能会读到未提交的数据
		写、写：可能会丢失修改
	解决方法：事务
		封锁技术，即事务在对某个数据对象进行操作之前，先向系统提出申请、对其加锁，加锁后事务就对该数据对象有了一定的空之轨迹，在事务是否它的锁之前，其他事务不能更新该数据对象
			封锁的类型：排他锁（写锁）：若事务A对数据对象A加上写锁，则只允许事务T修改和读取数据A，其他任何事务都不可以读取和修改数据A，，直到事务T释放了A 上的锁
				    共享锁（读锁）：若事务A对数据对象A加上读锁，则事务T可以读取A但不能修改A,，其他事事务只能再对A进行加读锁，不能加写锁，直到事务T释放了A 上的读锁。这就保证了其他事务可以读A，但在A释放之前不能修改A
	
59.Gdb调试线程
      线程的查看：
	//查看当前运行的进程ps aux|grep a.out
	//查看当前运行的轻量级进程ps -aL|grep a.out
	//查看主线程和新线程的关系pstree -p 主线程id
      线程栈结构的查看：
	1. 获取线程ID
	2. 通过命令查看所有线程栈结构 pstack 主线程ID
       	3.查看单个线程的栈结构 pstack 线程id
       利用gdb查看线程信息
	①将运行的进程附加到gdb调试器当中，查看是否创建了新线程：gdb attach 主线程ID
	②查看线程的一些信息：
		//1.查看进程：info inferiors
		//2.查看线程：info threads   *代表当前线程
		//3.查看线程栈结构（默认是主线程）：bt   
			thread apply 1 2 bt：让编号为1,2的线程执行命令bt，显示栈帧信息
			thread apply 【编号 编号】【command命令】：让编号为多少的线程执行command命令
			thread apply all command：让所有线程执行命令command
		//4.切换线程：thread n（n代表第几个线程）
       利用gdb调试多线程
	1.设置断点在线程1：
		//1. 设置断点：break 行号/函数名
		//2. 查看断点：info b
	2.执行线程2的函数，指行完毕继续运行到断点处
		1. 继续使某一线程运行：thread apply 2（第几个线程） n（next）：让线程2执行自己的代码
		2. 重新启动程序运行到断点处：r
	3.只运行当前线程
		1. 设置：set scheduler-locking on
		2. 运行：n
	4.所有线程并发执行
		    1. 设置：set scheduler-locking off（默认状态 ）
    		    2. 运行：n


	补充：gdb调试多进程
	gdb调试的两种方式：
		1.直接调试法：gdb拉取新的进程，从头开始跑程序
			gdb a.out
		2.附着调试法：程序正在运行，gdb附着到已经存在的进程调试
			gdb attach pid
			步骤：1.运行程序test.c，gcc test.c -o test -g程序在getchar()卡住
			          2.ps aux | grep test 查看test的pid
		 	          3.gdb attach pid   是gdb附着在进程上
		

60.对Shell脚本的了解。
	什么是shell脚本？shell脚本是包含包含一个或多个命令的文本文件的命令。
	为什么要使用shell脚本？系统管理员使用它来发出许多命令来完成任务。 所有命令都在文本文件（shell脚本）中一起添加，以完成日常例行任务。

61.中断、异常、系统调用
	中断：硬件设备对操作系统提出的请求
	异常：非法指令或者其他原因导致当前的指令执行失败之后的处理请求，是cpu对于CPU内的事件的响应
	系统调用：应用程序主动向操作系统发出的服务请求
	区别：
		源头：
			1.中断：外设
			2.异常：程序意想不到的行为
			3.系统调用：应用程序请求操作系统提供服务
		响应方式：
			1.中断：异步
			2.异常：同步
			3.系统调用：同步或异步
		处理机制
			1.中断：持续，对用户应用程序透明
			2.异常：杀死或者重新执行意想不到的程序指令
			3.系统调用：等待或阻塞
				
62.内核地址是什么
	虚拟地址3G~4G空间：0xc0000000~0xffffffff
		普通区：
		直接映射区：内核将内核空间前896M和物理空间的前896M进行直接映射。虚拟地址=3G+物理地址，从该区域分配内存不会触发页表操作来建立映射关系，可以申请到物理内存上连续的内存区域。高端内存是指896M开始到1G的虚拟地址空间
			ZONE_DMA(16M) ZONE_NORMAL 16M~896M
		高端内存区：896M~结束
		动态映射区（120M）：该区域有vmalloc函数分配，特点：线性空间连续，但是对应物理空间不一定连续
		永久内存区映射区（4M）：用于映射高端内存
		固定内存映射区（4M）：
	
63.中断上下文和进程上下文
	进程上下文：
		进程的组成：
			内核区：
				内核栈、进程控制块：建立进程=>建立PCB=task_struct结构体，
					task_struct结构体成员：void *stack：指向进程内核栈（和成员thread_info在一起），
						     void* mm：指向0~3G的用户空间，
			用户区：
				代码、数据、堆和栈
			cpu的寄存器：进程的现场信息
			页表
		进程上下文概念：进程在执行时，CPU的寄存器值、进程的状态以及堆栈中的内容等信息，被称为进程上下文，即进程的物理实体（用户空间的代码和数据）和支持进程运行的环境（PCB、内核栈、寄存器）合成为进程上下文，
		用户及上下文：由进程的程序块、数据块、运行时的堆和用户栈等组成的用户空间信息被称为用户级上下文
		系统级上下文：由进程标识信息、进程现场信息、进程控制信息、和系统的内核栈组成的内核空间信息被称为系统级上下文
		寄存器上下文（硬件上下文、进程的现场信息）处理器各寄存器的内容。
		在进行进程上下文切换时，操作系统把下降进程的寄存器上下文保存在该进程自身的系统级上下文的现场进程信息（内核栈）中
		何时发送进程上下文切换：（进程状态的变化）
			1.进程自身产生一个异常（系统调用），进程有运行态进入阻塞态，   ---------主动
			2.或时间片原因，会由时钟中断迫使该进程进行上下文切换，进程有运行态进入就绪态  ---------被动
			note：用户进程的切换必须在操作系统的参与和帮助下完成，也就是说必须由操作系统（内核）接管cpu的控制权的基础上，才能完成进程上下文切换
			          异常和中断都可看做中断
			总结：要想进程进程上下文切换，操作系统必须首先得到cpu控制权
			          操作系统何时得到控制权
				1.Trap：进程执行了一个系统调用
				2.Exception：进程执行另一个意外的操作(异常)
				3.Interrupt：硬件设备产生中断，申请操作系统，比如时间中断、I/O中断
		下降进程的现场和断点保存在哪里
			保存在内核栈中，pcb中有一个指针指向内核栈，便于寻找
		下降进程保存现场的过程：
			1.当前栈指针sp指针指向用户栈栈顶---->切换--->sp指针的值被保存在内核栈，但是sp新的值指向内核栈栈顶
			2.程序状态（psw）---->切换--->内核栈
			3.断点（原来进程的pc寄存器值）---->切换--->pc的值保存在内核栈，但是pc新的值指向内核的中断处理程序
			4.通用寄存器---->切换--->内核栈中的中断处理程序中
		模式切换和进程切换：
			1，模式切换cpu还在同一个进程中或中断上下文，只是进程从用户态进入内核态，仅仅是保存了进入内核前的现场，不改变当前进程的空间等信息
			2，要发生进程切换，是指CPU转而去执行另一个进程，改变了当前进程的空间信息：
				a保存当期进程的硬件上下文
				b修改当前进程的pcb，比如进程状态的变化，并将该进程加入相关队列
				c调度另一个进程
				d修改被调度进程的pcb，改变其状态（系统级上下文）
				e⁮将‘当前进程’的存储管理数据改为被调度进程的存储管理数据信息（如页表）（切换用户级上下文）
				f恢复新进程的硬件上下文，让pc执行进程代码


	中断上文：硬件通过中断触发信号，导致内核调用中断处理程序，进入内核空间，这个过程中，硬件的一些参数和变量要传给内核，内核通过这些参数进行中断处理。中断上文可以看做就是硬件传递过来的这些
		参数和内核需要保存的一些其他环境
	中断下文：执行在内核空间的中断服务程序。当工作在用户态的进程想访问某些内核才能访问的资源时，必须通过系统调用或中断才能进入内核态，有内核代替其执行。
	总结：中断上文对于实时性要求比较高的部分
	           中断下文做具体的，比较耗时的事情，属于中断的具体处理部分
64,解释http报文格式
	http有两类报文：请求报文和应答报文
	http请求报文	
		http请求报文由请求行、请求头部、空行和请求数据组成
		请求头：由请求方法字段、URL字段和http协议版本字段组成，请求方法求GET、POST、HEAD、PUT、OPTION、TRACE、CONNECT
			常见的请求方法：GET，当客户端要从服务器中读取信息时，使用GET方法，请求指定页面信息
				           POST：当客户端给服务器提供较多信息时，使用POST请求，数据被包含在请求体中，以名称和值的形式出现
				           HEAD：类似于get请求，只不过返回的是响应中没有具体内容，用于获取报头
			请求头部：包含若干个属性，服务器据此得到客户端信息 格式：首部字段：值
				请求首部字段：
					host：请求资源所在服务器
					Accept：
					Accept-Charset：可接受的字符集
					Accept-Encode：可接受的内容编码
					connection：close，连接的管理，表示服务器发送完后就可释放连接；
			                       
	http响应：
		由状态行、响应头部、空行、响应体组成
		状态行：http协议版本、状态码、状态码的描述
		响应头部：
		空行	
		响应体：服务器会给客户端的文本信息
	一次http请求所经历的步骤
		tcp建立三次连接后：web浏览器向web服务器发送请求命令
				web浏览器发送请求头
				web浏览器发送空行表示请求头发送结束
				应答：web服务器发送状态行，包括协议版本号、状态码
				web服务器发送响应头部信息，并发送空行后
				web服务器发送实际数据给浏览器
				web服务器关闭连接
67.为什么视频电话使用udp？如何通过应用层解决UDP协议的不可靠性；tcp协议如何保证可靠性
	udp应用场景：实时性和效率高
		当应用程序对传输的可靠性要求不高，对传输速度和延迟性要求高时，使用udp协议，视频电话时，偶尔丢失一两个数据包不影响体验
		游戏开发（及时战略游戏）
		物联网（检测类传感器，频繁上报数据，做到节约资源）
	udp的可靠性：在应用层添加应答机制
		       在应用层添加超时重传机制
		       在应用层 滑动窗口机制
	sendto函数
		sendto函数不会进行数据分片，这里必须进行数据分包，一般保证udp的数据包的大小为1400/500字节
				MTU为46~1500字节，IP报头最小20字节，udp报头最下8字节，udp的数据包最大为1472，但容易出错，
	recvfrom函数：
		sendto      发送：1400字节->1400字节
		recvfrom  接收：1000字节->1000字节（每次都会丢掉400字节）
		总结：recvfrom每次都需要接收一个完整的报文，如果不接受完整，则剩余部分被丢弃
	    	          recv接收多少次都可以，因为TCP是一个字节流传输
	举例：客户端要传输6452字节数据给服务器
		1.需要进行分片传输，每片的数据位1400字节，最后一个分片为912字节
		2.需要对分片进行编码   
			
		
68.Linux下的系统的调用，软件中断。
	系统调用的作用：
		1.允许向进程提供虚拟化的系统
		2.为用户空间提供硬件接口的一个抽象
		3.保证整个操作系统运行环境的安全性和稳定性
	系统调用处理函数：
		1.在linux中，系统调用时用户空间访问内核的唯一合法手段。用户进程在用户空间执行，系统调用时内核代码，不能直接调用
		2.操作系统是通过中断从用户态切换到内核态。中断就是一个软件或硬件请求。中断的两个属性：中断号和中断处理程序。操作系统维护了一张中断向量表，存储了所有中断的中断处理程序地址。
		3.系统调用都是通过软件中断实现的，x86系统上使用第128（$0x80）号中断（int 0x80指令），对应的系统调用处理函数为system_call( )
		4.新的x86处理器提供了专门的系统调用指令sysenter比int指令更高效
	操作系统有很多系统调用，对于同一个中断号如何处理有多个不同的系统调用？
		1.linux每个系统调用都有相应的系统调用号作为标识，系统调用号全局分配，不可改变。
		2.没有实现的系统调用依然占用相应的系统调用号，但是程序执行一个特殊的系统的系统调用函数sys_ni_syscall（），返回-ENOSYS
		3.内核维护一张系统调用表，sys_call_table，表中元素是系统调用函数的起始地址，系统调用号是表的偏移量，在x86上，系统调用号是通过eax寄存器传递给内核的。
		4.一旦将系统调用号放入寄存器，执行了int 0x80后，进入到内核空间，system_call()会检查系统调用号是否正确，若系统调用没有实现，则返回-ENOSYS，否则根据系统调用表调用相应的系统调用
	系统调用是需要提供参数的，并且具有返回值，这些参数是如何传递的
		1.一般参数传递（<=5）
			在linux中，按顺序使用ebx、ecx、edx、esi、edi寄存器，最多传递5个参数
		2.超过5个参数
			将其中一个寄存器作为地址指针，指向用户空间存储区中参数的起始地址，
		3.返回值放在eax寄存器中，0表示成功
		

69.管道的实现应该注意什么问题，怎么解决
	1.读管道的时候，如果管道中没有数据，当管道的写端都关闭的时候，read会返回0
				            当写端没有全部关闭的时候，read阻塞等待
	2.写管道的时候，当读端全部关闭时，进程异常终止（GIGPIPE）
		          当读端没有全部关闭，如果管道已满，则write阻塞
				                         未满，write成功
	3.原则上管道可以由一个读端多个写端，或一个写端多个读端，但这种情况应该尽量避免
	4管道是一种半双工的通信方式，要实现双向通信需要建立2个管道
	
70.除了socket 还有什么可以创建网络通讯

71.怎么防止内存覆盖

72.IIc详解
	1.IIC总线是一种多主机总线，IIC总线上可以挂载多个设备：多个主机（单片机），多个从机（外设），主机有权发起和结束一次通信，而从机只能
	   被主机呼叫，当总线上有多个主机同时启用总线时，IIC也具备冲突检测和仲裁功能来防止错误产生。
	2.每个连接到iic总线上的器件都有一个唯一的地址（7bit），且每个器件都可以做为主机和从机（同一时刻只能有一个主机），主机和其他器件之间的数据传输可以由主机发送到其他器件，
	这是主机为发送器，总线上接收数据的器件为接收器
	3iic通信过程：
		1.主机发送起始信号启用总线（其他主机就不会启用总线了，其他从机就知道有主机要通信了）
		2.主机发送一个字节数据指明从机地址和后续字节的传送方向（最低位为0表示主机给从机发，1表示从机给主机发，高7位为从机地址）
		3.被寻址的从机发送应答信号回应主机（）
		4.发送器发送一个字节
		5.接收器发送应答信号回应发送器
		循环步骤4.5（通信顺序不能变）
		n.通信完成后主机发送停止信号释放总线（其他主机也能接收到，其他主机就可以启用总线了，从机也接收到了）
	4.iic总线寻址方式
		iic总线发送的数据是广义的，既包含地址，又包含真正的数据
		主机在发送起始信号后必须先发送一个字节的数据，高7位表示从机地址，最低位表示后续字节的传递方向，0表示主机发送数据，
		1表示主机接收数据；总线上所有的从机接收到该字节数据后都将这7位地址与自己的地址进行比较，如果相同，则认为自己被主机寻址，
		然后根据最低位将自己定义为发送器或接收器
	5.起始信号：scl为高电平时，sda由高到低
	   停止信号：scl为高电平时，sda由低到高
	   字节传送和应答：iic总线通信时每个字节为8位，数据传送时，先传送最高位，后发地位，发送器发送完一个字节后，接收器必须发送以为应答位来回应发送器，即一帧数据共9位
	   	当一个字节发送完了后，应答信号是在第九个时钟SCL为低电平期间，接收器发送低电平到数据线，在SCL为高电平时，发送器从SDA上读取应答信号
	   同步信号：iic总线在进行数据传送时，时钟线SCL为低电平期间发送器向数据线上发送一位数据，在此期间数据线上的信号允许变化，时钟线SCL为高电平期间接收器从数据线上读取
		一位数据，在此期间数据线上的信号不允许发送变化，必须保持稳定。
	6.典型iic时序
		主机向从机发送数据：
			S->从机地址+0->从机A->主机数据->从机A->主机数据->从机A/~A->P
		从机向主机发送数据：
			S->从机地址+1->A->从机数据->主机A->从机数据->主机不应答~A->P
		主机先给从机发，然后从机给主机发数据
	7.iic仲裁
		iic仲裁分为两部分：SCL同步和SDA的仲裁
		SCL同步：由于总线具有线与的逻辑功能，只要有一个期间发送低电平，总线就位低电平，所有期间发送高电平，总线才会高电平
		SDA仲裁：SDA仲裁也是建立在总线具有线与的逻辑功能原理上的，主机在发送1位数据后，比较总线上的数据和自己发送的额数据是否一致，一致就继续发送，不一致退出竞争
73.uart总线详解
	1.是一种串行异步通信协议，有两根数据线，  
	2.波特率：串口通信速度单位，单位为bps（每秒传送的二进制位）
	3.UART帧格式：
		空闲位（高电平）->起始位（1位，低电平）->数据位（先发低位，再发高位，一般习惯发8位，可以发5、6、7、8位）->校验位（可有可无）->停止位（1位或1.5位或2位，高电平）->空闲位
		note：串口协议规定：数据线在空闲的时候为高电平；串口一次最多发一个字节，要发多个字节，就发送多次，这是因为串口通信的双方没有一个同一的时间基准，时间长的话就有一个累计误差。
74.SPI详解
	1.概念：是一种高速、全双工、同步的通信总线；采用主从方式工作，一般有一个主设备（管理总线）和一个或多个从设备，SPI需要至少四根线，分别是MISO（主设备输入，从设备输出）、MOSI（主设备输出，
		从设备输入）、cs（片选信号，每个从机需要一个片选信号，对于主机而言，有多个从设备就有多个cs）、SCLK（时钟）。
	2.寻址方式：当主设备要和某个从设备进行通信时，主设备需要先向对应从设备的片选线上发送使能信号，表示选中该从设备
		note：怎么判断cs是高电平使能和低电平使能？   cs：高电平，~cs：低电平使能
	3.通信过程：SPI总线在进行数据传输的时候，先传输高位，后传送地位，一个字节传送完成后无需应答位即可开始下一个字节的传送；SPI总线采用同步方式工作，时钟线在上升沿或下降沿的时候发送器向数据线上发送
		数据，在紧接着的下降沿或上升沿接收器从数据线上读取数据，完成一位数据传送，八个时钟周期即可完成一个字节数据的传送。
	4.极性和相位：
		SPI总线有四种不同的工作模式，取决于极性（CPOL）和相位（CPHL）这两个因素，即SPI有四种工作模式
		CPOL表示SCLK空闲时的状态	
			CPOL=0：空闲时SCLK为低电平
			CPOL=1：空闲时SCLK为高电平	
		CPHL表示采样时刻
			CPHL=0：每个时钟周期的第一个时钟沿采样，即上升沿
			CPHA=1：每个时钟周期的第二个时钟沿采样
		总结 ：
			1.CPOL=0、CPHL=0：表示下降沿发送方发数据，上升沿接收方读数据
			2.CPOL=0、CPHA=1：表示上升沿发送方发数据，下降沿接收方读数据
			3.CPOL=1、CPHL=0：表示上升沿发送方发数据，下降沿接收方读数据
			4.CPOL=1、CPHA=1：表示下降沿发送方发数据，上升沿接收方读数据
		对于从机，出厂时工作模式固定，所以我们需要对主设备的极性和相位进行配置，和从设备保持一致
	5.IIC和SPI比较
		相同点：
			1.均采用串行、同步方式
			2.均采用TTL电平，传输距离和应用场景类似
			3.均采用主从工作方式
		不同:
			1.iic是半双工，spi是全双工
			2.iic有应答机制，SPI没有应答		
			3.寻址方式不同，iic通过向总线广播从机地址进行寻址（节省硬件资源），spi通过向从机发送使能信号来寻址（节省时间）
			4.iic的时钟极性和时钟相位固定，spi的时钟极性和时钟相位可调
75、
	
76.长链接和短连接，有什么区别？
	短连接：在http1.0版本的时候，客户端与服务器完成一个请求和响应之后，会将之前的TCP连接断开，下次请求的时候又重新建立TCP连接
	长连接：在http1.1版本后带来一个新功能，在客户端与服务器完成一次请求和响应之后，允许不断开TCP连接，这意味着下次请求就直接使用这个TCP连接而不再重新建立TCP连接
	note：长连接指的是一次TCP连接允许多次HTTP会话，HTTP永远都是一次请求和响应，会话结束，HTTP本身不存在长连接之说
	           http请求的头部信息中：Connection：keep-alive表示服务器和客户端建立长连接
	长连接优缺点：
		优点：当网站中有大量资源就开启长连接
		缺点：当客户端请求一次之后不再请求，而服务器却开着长连接资源被占用，这样严重的浪费资源
77.中断函数与普通函数有啥区别
	中断服务函数应该注意的四大点：
		1.中断服务函数不能传参
		2.中断服务函数不能有返回值
			中断服务函数的调用是硬件级别的，当中断产生，pc指针强制跳转到对应的中断服务函数入口
		3.中断服务函数应做到短小精悍
		4.不要在中断函数中调用printf函数，会带来重入和性能问题
78.tcp、ip的帧格式
	ip协议：如果没有选项的话，ip首部20个字节
		4位版本号：IPV4、IPV6
		4位首部长度：ip header长度没有选项的话，一般为5（5*32bit=20字节）
		8位服务类型：一般没有使用
		16位总长度：ip报文总长度，ip首部+数据长度
		16位标识：每传送一个ip数据报，标识符加1，ip报文唯一的id，分片报文的id相同，便于进行重组
		3位标志：表明是否分片，R、DF、MF，目前只用后两位，DF为1，不分片，0分片；MF为1表示更多的片，为0表示这是最后一片
		13位片偏移：本分片的数据在原先数据报文中相对首位的偏移位，（需要乘以8才是原来的偏移）
		8位生存时间：TTL，IP报文所允许通过的路由器的最大数量
		8位协议：指出ip报文携带的数据使用的是哪种协议，ICMP：1，IGMP:2，TCP：6，UDP：17
		首部校验位：计算ip头部的校验和，检查报头的完整性
		源ip地址：表示ip数据报的源端设备
		目的ip地址：目的ip地址
		选项：
		数据：上层的报文，如TCP报文、UDP报文
	TCP协议：如果没有选项的话，tcp首部20个字节
		16位源端口号：标识一台计算机中唯一一个应用程序
		16位目的端口号
		32位序号：序号是本报文段发送的数据组的第一个字节的序号，每一个字节一个序号。比如一个报文段的序号为300，这个报文段数据部分有100个字节，则下一个报文段的序号为400
		32位确认序号：指明下一个期待收到的字节序号。确认号只有当ACK标志位为1时才有效
		4位首部长度：如果没有选项的话，就是20个字节，最多为1111（15）*4  = 60个字节
		保留6位：
		6个标志位：URG：紧急指针标志、ACK：确认序号标志、PSH：为1表示接收方收到数据后应尽快将该报文交给应用程序，而非在缓冲区排队、RST：重置连接标志、SYN：请求连接标志、FIN：断开连接标志
		16位窗口大小：用来告知发送端接收端的缓存大小，依次控制发送端发送数据的速率，从而达到流量控制
		16位校验和：奇偶校验，此校验和是对整个的TCP报文段，包括头部和数据，以16位字进行计算，接收端验证
		16位紧急指针：只有URG有效时，该指针才有效
		选项：
		数据：
	UDP协议：
		16位源端口号：
		16位端口号
		16位UDP长度：
		16位UDP校验和：
	以太网帧协议：首部14字节，尾部4字节
		6位目的MAC地址：
		6位源MAC地址：
		2位类型：0800（IP数据报），0806（ARP请求），0835（RARP请求）
				
		
79.linux下查找文件的命令
	1.find ：按照文件格式查找
		按文件名查找：find 目录  -name "*.txt"
		按文件大小查找find /pathname  -size +1000k -
		按文件类型查找：find 目录  -type "f"
		按文件权限查找：
	2.grep按照文件内容查找：
	3.which、whereis命令：
		which：找到某一命令所在的位置，它是通过PATH路径进程查找的，找的是某一命令的可执行二进制文件
		which：找到某一命令所在的位置，它是通过PATH路径进程查找的，但他还会搜索其他的内容，加了-b就只查找二进制文件
80.开发一个功能需要哪些步骤要做些什么，
	1.需求分析
		工具用户需求，了解整个系统要实现的大致的大模块功能，大模块功能中的小模块功能，对项目需求整体进行评审
	2.设计
		1.概要设计：概要设计报告系统的基本流程设计、系统的组织结构、系统模块划分、功能分配、接口设计、出错设计等
		2.详细设计：在概要设计的基础上，需要进行软件系统的详细设计，在详细设计中，描述实现具体模块用到的算法、数据结构、系统各个层次中的每个小模块和自程序的设计考虑等等
	4.编码实现
		根据具体的设计对各个模块开始具体的编码工作，实现其功能
	5.代码审核
	6.自测试
	7.联调
	8.代码规范检查
	9.代码提交
81.单播、广播和组播
	单播：
		主机之间一对一的通讯模式，网络中的交换机或路由器只转发数据，不复制。网络中的交换机或路由器根据目标地址选择传输路径，若10个客户机需要相同的数据，则服务器需要逐一发送，重复10次相同的工作
		举例：收发邮件
	组播：
		主机之间一对一组的通讯模式，即加入了同一个组的主机之  间可以接收到此组内的所有数据，网络中的交换机或路由器只向有需求者复制并转发其所需数据。主机可以向路由器请求加入或退出某个组，网络中的
		交换机或路由器有选择的复制并传输数据，即只将组内数据传输给那些加入组的主机，这样可以一次将数据传输给多个有需要（加入组）的主机，又能保证不影响其他不需要（未加入组）的主机的其他通讯
		举例：视频会议
	广播：
		主机之间一对所有的通讯模式，网络对其中每一台主机发出的信号都进行无条件复制并转发，所有主机都可以收到所有信息（无论是否需要），不用路径选择。
		举例：有线电视
82.文件系统
	1.低级格式化：划分磁道和扇区-----每个磁道的扇区是相等的
	2.高级格式化：构建一个文件系统（一组数据结构）
		分区表：划分磁盘-->partitions（分区）
		目录：
	命令fdisk -l查看当前系统磁盘数量
	Disklabel type：dos=>MBR分区
	Disk indentifier：disk id
	Device:
		/dev/sda:第a块硬盘设备
		/dev/sda1:第a块硬盘设备的第一个分区   （启动分区，里面有硬盘主引导记录（MBR，446字节）和分区表（64字节））
		boot：是不是启动分区（*）	
		start：起始扇区号
		end：最终的扇区号
		sectors：扇区数量
		size
		id：分区类型编号（83->liunx）
		type：分区类型编号对应的文字描述
83.进程间通信共享内存资源竞争问题
	1.临界资源：一次仅允许一个进程访问的共享资源
	   临界区：访问临界资源的那段代码
	2.临界资源访问方式
		1.硬件方式：
			关中断：每个进程进入临界区之后关闭所有中断，这样就不会把cpu切换到另一个进程了，离开前才重新打开中断------一个cpu的情况
			相关指令
		2.软件方式：
			1.锁机制
			2.信号量机制（P-、V+操作）
	3.信号量S
		semget：创建和访问一个信号量集
		semctl：信号量控制函数
		semop：改变信号量的值
		sem_p：
		sem_v：

85.wireshark抓包工具
	界面：
		1.display filter显示过滤器
			1.协议过滤：比如TCP、ip
			2.IP过滤：比如ip.src == 192.168.1.102 or ip.dst == 192.168.1.102
			3.端口过滤：tcp.port == 80   tcp.srcport == 80 
			4.http过滤：http.request.method == "GET"
			5.逻辑运算符and or
		2.packet list pane：封包列表
			编号、事件戳、原地址、目标地址、协议、长度、封包信息
		3.packet details pane：封包详细信息，
		4.dissector pane：16进制数据
		5.miscellanous：地址栏（杂项）	
86.临界区的底层实现
87.排序算法和查找算法时间复杂度
	排序：
		冒泡：O(N^2)
		选择：O(N^2)
		快排：O(nlog(n)) 
		插入：O(N^2)	
	查找：
		顺序：O(N)，条件是有序或者无序
		二分：O(logn)，条件是有序数组
		分块：O(logn) ，条件是有序或者无序	
	链表排序算法：
		冒泡：
		选择：
		插入：
		快排：	
88.数据包的分片和重组
	数据包的分片：源主机和中间的路由器
		1.在TCP/IP分层中数据链路层用MTU来限制所能传输的数据包的大小。MTU是指一次传送的数据最大长度，不包括数据链层数据帧的帧头，当发送的ip数据报的大小超过了MTU时，
	  	 ip层就需要对数据进程分片，否则无法发送成功。
		2.ip分片发生在ip层，不仅源主机会进行分片，中间的路由器也有可能会进行分片，因为不同的网络的MTU是不一样的。如果传输路径上的某个网络的MTU比源网络的要小，路由器就
		   可能对ip数据报再次进行分片。而分片数据的重组只会发生在目的端的ip层
		3.ip层是没有超时重传机制的。如果ip层对一个数据包进行了分片，只要有一个分片丢失了，只能依赖于传输层重传结果所有的分片都要重传一遍，这个代价有点大。由此可见，ip分片会
		   大大降低传输层传输数据的成功率，所有要尽量避免ip分片。
	数据包的重组：目的主机
		目的主机收到所有分片后，对分片依次进行重新组装还原的过程叫做ip数据包重组
		ip协议规定，只有最终的目的主句才能对分片进行重组

89.malloc分配内存失败的原因
	1.内存不足
	2.前面程序使用malloc函数时发生了内存访问越界，对未知的内存做了操作，致使maolloc不能继续分配内存
		解决方法：查找最近一次malloc的地方，查看这次malloc申请内存都做了什么，是否存在越界
90.malloc vmalloc kmalloc区别
	1.kmalloc、vmalloc是分配内核的内存，malloc是分配用户的内存
	2.kmalloc保证分配的内存在物理空间上是连续的，vmalloc和malloc保证虚拟内存上的连续
	3.kmalloc能分配的大小有限，vmalloc和malloc能分配的大小相对较大

91.互斥锁、读写锁
	互斥锁：用于保证任何时候，都只能有一个线程访问该对象。当获取锁失败的话，线程会进入睡眠，等待锁释放时被唤醒
	读写锁：分为读锁和写锁，处于读操作时，可以允许多个线程同时获得读操作。但同一时刻只能有一个线程可以获得写锁。写锁或阻塞其他读写锁，当一个线程获得写锁在写时，读锁也不能被其他线程获取，写锁优先级高
	区别：
		1.读写锁区分读和写，互斥锁不区分
		2.互斥锁同一时间只允许一个线程访问对象，无论读写；读写锁同一时间只允许一个写，但允许多个读
	自旋锁：在任何时刻都只有一个线程访问，党史当获取锁操作失败后，不会进入睡眠状态，而是会在原地自旋，知道锁释放。这样节省了线程从睡眠到被唤醒期间的消耗，在加锁事件短暂的环境下会极大的提高效率，但如果加锁时间长的话会非常浪费资源。
92.硬链接与软连接
	为了解决文件共享问题，引入软链接和硬链接
	若1个inode号对应多个文件名，则为硬链接，硬链接这块就是同一个文件使用了不同的别名，用ln创建
	若文件用户数据块存放的内容是另一个文件的路径名所指，则改文件为软链接，软链接是一个普通的文件，有自己独立的inode，但是其内部数据比较特殊
93.析构函数什么时候调用
	1.当在main里面声明了一个类A，那么~A会在main函数结束时调用
	2.如果在自定义的函数中声明A对象的话，函数调用结束的时候调用函数，
	3.delete指向A的指针的时候
	4.显式调用析构函数的时候
	作用：
		析构函数的作用不是删除对象，而是在撤销对象占用的内存之前完成的一些清理工作，使得这部分内存可以被程序分配给新对象使用

94DNS（domain name system域名系统）原理
	DNS是因特网使用的命名系统，用来把人们使用的机器名字转化为ip地址
	用户与因特网上某台主机通信时，显然不愿意使用难记复杂的32位ip地址，大家更愿意使用容易记忆的主机名字。但是机器在处理ip数据报时，并不是使用域名，而是ip地址，因为域名长度不固定，处理起来比较麻烦
	因特网规模庞大，采用的是层次树状结构的命名方法，并使用分布式域名系统DNS，采用客户端服务器方式。DNS使大多数名字都在本地解析，少量解析需要在因特网通信。
	域名到ip地址的解析是由分布在因特网上的许多域名服务器共同完成的。域名服务器程序在专设的节点上运行，而人们也常把运行域名服务器程序成为域名服务器
	域名到ip的解析要点：当一个应用需要把主机名解析为ip地址时，该应用进程就调用解析程序，并成为DNS的一个客户，把等待解析的域名放在DNS请求报文中，以UDP用户数据报方式发给本地域名服务器，本地域名服务器查找域名后，把对应ip地址放在
		应答报文中返回。应用程序获得ip地址后即可通信。若本地域名服务器不能应答该请求，则此域名服务器就暂时称为DNS的另一个客户，并向其他域名服务器发出查询请求。这个过程知道找到能够回答该请求的域名服务器位置。
	域名结构：
		任何一个在因特网上的主机或路由器都有域名，每一个域名都是由标点和序列组成，各标点之间用.隔开，比如mail.cctv.com，其中com是顶级域名，cctv是二级域名，mail是三级域名
	域名服务器分类：
		根域名服务器：所有的根域名服务器都知道所有的顶级域名服务器的域名和ip
		顶级域名服务器：管理在该顶级域名服务器下注册的二级域名域名
		权限域名服务器：
		本地域名服务器：
	域名解析过程：
		1.主机向本地域名服务器的查询一般都是递归查询。即如果主机所查询的本地域名服务器不知道被查询的域名的ip地址，那么本地域名服务器就以DNS客户端的身份继续发出查询请求报文（即替主机查询），
		   而不是让主机自己进行下一步查询。
		2.本地域名服务器向根域名服务器的查询是迭代查询，即当根域名服务器收到本地域名服务器发出的迭代查询请求报文时，要么给出ip地址，要么告诉本地域名服务器下一步应该向哪一个域名服务器进行查询，
	 	   然后让本地域名服务器进行后续查询。
95.https原理介绍
	http风险：
		被窃听的风险：第三方可以截获并查看你的内容
		被篡改的风险：第三方可以截获并修改你的内容
		被冒充的风险：第三方可以伪装成通信方与你通信
	
	非对称加密：公钥和私钥，公钥是公开的，所有人都知道，用公钥进行加密，私钥是保密的，只有持有者知道，用私钥进行解密，通过公钥加密的内容，只有通过私钥解开
	bob和它的朋友pat、susan、doug
		1.bob弄到两把钥匙：公钥和私钥
		2.私钥自己保留，公钥复制成3分，给它的朋友
		3.sunsan和bob讨论问题，susan先把自己的内容（明文）用公钥加密，然后把加密的内容传给bob。bob收到后，用私钥解开即可
		4.bob给susan回信。为防止内容被篡改，它先对新的内容用hash算法做一次处理，得到一个字符串哈希值，又用自己的私钥对哈希值加密得到一个签名，然后把签名和信（明文）一起给susan
		5.Susan收到信后，先用bob给的公钥对签名进行解密，得到哈希值A，然后Susan用了同样的哈希算法对信的内容进行一次哈希处理，得到另一个哈希值B，若A和B相等，，则确认信是bob写的，且没有被篡改
		6.bob通过网络把公钥发送给Doug，但是Jerry截获了公钥，并伪装成bob与Doug通信；
		7.bob发现自己的公钥被截获，为避免公钥被截获，它去第三方权威机构“证书中心”做认证，证书中心用自己的公钥对bob的公钥和其他信息做了一次加密，这样bob通过网络将数字证书传递给它的朋友后，
		  小伙伴们先用认证中心的 公钥解密证书，这就就可以获得bob安全的公钥了
	https通信过程：
		1.浏览器发往服务器的443端口发起请求，请求携带了浏览器支持的加密算法和哈希算法
		2.服务器收到请求，选择浏览器支持的加密算法和哈希算法
		3.服务器将数字证书返回给浏览器，这里的数字证书可以是向某个机构申请的，也可以是自制的
		4.浏览器进入数字机构认证环节，这一部分是浏览器内置的TLS完成的
			4.1首先浏览器会从内置的证书列表索引，找到服务器下发证书对应的机构，如果没有找到，此时就会提示用户该证书不是由权威机构颁发，是不可信任的，如果查到了对应的机构，则取出该机构颁发的公钥。
			4.2用机构证书公钥解密证书的内容和签名内容报告网站的网址、网站的公钥、证书的有效日期等，浏览器会先验证证书签名的合法性，认证通过后，浏览器就可以使用证书中的网站公钥了
		5.浏览器生成一个随机数R，即秘钥R，并使用公钥对随机数进行加密
		6.服务器用自己的私钥进行解密，得到R
		7.服务器以R为秘钥使用了对称秘钥算法加密网页内容并传送给浏览器
		8.浏览器以R为秘钥使用之前约定好的解密算法获取网页内容。
	note：前5步其实是https的握手过程，主要验证了服务端证书（内置公钥）的合法性，这个过程用到了一次非对称加密算法，主要是用来保护客户端生成的用于对称加密的随机数私钥。后续内容都是通过一开始约定好的对称加密算法进行的
	
96.软中断和硬终端的区别
	1.硬件中断是由外设硬件发出的，具有随机性和突发性；软中断是执行中断指令产生的，无外部施加中断请求辛哈，因此中断的发生不是随机的，而是由程序安排好的
	2,硬中断的中断号是由中断控制器提供的，软中断的中断号是由指令直接给出，无需使用中断控制器
	3.硬中断是可以屏蔽的，软中断不可屏蔽
	4.硬件中断处理程序要确保它能快速地完成任务，这样程序执行时才不会等待较长事件，成为上半部
	5.软中断处理程序处理硬中断未完成的工作，是一种推后执行的机制，属于下半段。
	
97.面向对象封装、继承、多态的作用
	封装：
		隐藏内部细节，对方提供公共的访问方式
		提供安全性，提高代码的复用性
	多态：
		不必编写每个子类的功能调用，可以直接把子类当做父类看，屏蔽子类间的差异，提高代码的通用率
		父类引用可以调用不同子类的功能，提高了代码的扩充性和可维护性
		
98.虚函数的作用
	虚函数是采用virtual修饰的函数
	主要作用是让成员函数一般化，用基类的指针指向不同的派生类的对象时，基类指针调用其虚成员函数，
团队成员不配合怎么办
	1.因为成员自身技术问题，主动关心成员的开发进度和技术上的问题，一起协商，寻找解决方法。了解每个成员的特点，合理分配任务，较好的亲和力，融入团队，力往一处使
	2.成员性格问题：首先分析他为什么和我作对，出于利益还是收到威胁或是不喜欢我的性格等等，然后对症下药；第2步是与它所在部门主管沟通，让它的主管处理；第3，如果仍然无法解决，汇报上司，去交流、协商。

		
		
		
		
		
		
	

		
	
		
	
		

		
	
	
		
	
		
	


